{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39de1b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_theme(style=\"darkgrid\")\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae0f1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (7,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f377ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd00c410",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_validate, GridSearchCV\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd82795",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import beta\n",
    "from scipy.stats import f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f3164e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import cycle\n",
    "from pca import pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2292b8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Machine Learning Modules\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f781188",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Pandas version: \", pd.__version__)\n",
    "print(\"Seaborn version: \", sns.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea97b8f",
   "metadata": {},
   "source": [
    "Dataset\n",
    "The \"Admission Prediction\" dataset is used for prediction of admission to postgraduate program using below mentioned data vairables.\n",
    "The data consists of ~400 observations. Every observation is described by 7 feature columns which can be used for prediction.\n",
    "GRE Score: Scores from the Graduate Record Examinations, an important factor in graduate admissions.\n",
    "TOEFL Score: Test scores from the Test of English as a Foreign Language, indicating the applicant's proficiency in English.\n",
    "University Rating: A rating of the university that might correlate with the competitiveness or prestige of the program.\n",
    "SOP (Statement of Purpose): A qualitative measure of the applicant's statement of purpose, reflecting preparedness and intent.\n",
    "LOR (Letter of Recommendation): Strength of the letters of recommendation.\n",
    "CGPA: Undergraduate cumulative grade point average, a critical indicator of academic performance.\n",
    "Research: A binary indicator of whether the applicant has research experience, which can be crucial for research-oriented programs.\n",
    "Chance of Admit\n",
    "The original dataset can be found at - https://www.kaggle.com/datasets/akshaydattatraykhare/data-for-admission-in-the-university"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5369b439",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loads csv file into pandas dataframe\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/VishnuSharan-T/INSE6220/main/Admission-prediction.csv')\n",
    "df = df.drop(columns=['Serial No.'])\n",
    "# Renaming & converting the CGPA to percentage for convenience\n",
    "df.rename(columns={'CGPA': 'Percentage'}, inplace=True)\n",
    "df['Percentage'] = df['Percentage'].apply(lambda x: int(x * 10 * 9.5 / 10))\n",
    "# Converting the Chance of Admit value to an integer value\n",
    "df['Chance of Admit '] = df['Chance of Admit '].apply(lambda x: int(x * 100))\n",
    "df['SOP'] = df['SOP'].apply(lambda x: int(x))\n",
    "df['LOR '] = df['LOR '].apply(lambda x: int(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c3ee9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.head(n=30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b74566d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01308ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df.index))\n",
    "print(\"Number of duplicated rows is: \", df.duplicated().sum())\n",
    "print(\"Number of rows with NaNs is: \", df.isna().any(axis=1).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2112550",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df, hue='Chance of Admit ')  # Visualize data distribution using pair plot\n",
    "plt.ylabel('')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8294932a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df['Chance of Admit ']\n",
    "target = df['Chance of Admit '].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2bdfd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['Chance of Admit ']) #drop column class to standardize data\n",
    "print(X.head(10))\n",
    "print(X.describe().transpose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b022de",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs = StandardScaler().fit_transform(X)                   #This is done to retain the column names after standardization\n",
    "df = pd.DataFrame(Xs)\n",
    "df.columns = X.columns\n",
    "observations = list(df.index)\n",
    "print(observations)\n",
    "variables = list(df.columns)\n",
    "print(variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbdeb048",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA()\n",
    "pca.fit(df)\n",
    "Z = pca.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b429f837",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1(Alpha)->0,  2(Beta)->1, 3(Gaama)->2\n",
    "idx_Alpha = np.where(Y == 0)\n",
    "idx_Beta = np.where(Y == 1)\n",
    "idx_Gaama = np.where(Y == 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b53ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt. figure()\n",
    "plt.scatter(Z[idx_Alpha,0], Z[idx_Alpha,1], c='r', label='Alpha (0)')\n",
    "plt.scatter(Z[idx_Beta,0], Z[idx_Beta,1], c='g', label='Beta (1)')\n",
    "plt.scatter(Z[idx_Gaama,0], Z[idx_Gaama,1], c='b', label='Gaama (2)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521cd39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.legend()\n",
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce7869c",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = pca.components_.T\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.scatter(A[:,0],A[:,1],c='r')\n",
    "plt.xlabel('Z1')\n",
    "plt.ylabel('Z2')\n",
    "for label, x, y in zip(variables, A[:, 0], A[:, 1]):\n",
    "  plt.annotate(label, xy=(x, y), xytext=(-2, 2))\n",
    "  textcoords='offset points',\n",
    "  ha='right',\n",
    "  va='bottom',\n",
    "  bbox = dict(boxstyle='round', pad = 0.5, fc = 'yellow', alpha = 0.5)\n",
    "  arrowprops = dict(arrowstyle='->', connectionstyle='arc3, rad=0')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8ef1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eigen Values\n",
    "A = pca.components_.T\n",
    "Lambda = pca.explained_variance_\n",
    "x = np.arange(len(Lambda)) + 1\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.plot(x, Lambda/sum(Lambda), 'ro-', lw=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3216c633",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Explained Variance\n",
    "ell = pca.explained_variance_ratio_\n",
    "ind = np.arange(len(ell))\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.bar(ind, ell, align='center', alpha=0.5)\n",
    "plt.plot(np.cumsum(ell))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4e7983",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Biplot\n",
    "A1 = A[:,0]\n",
    "A2 = A[:,1]\n",
    "Z1 = Z[:,0]\n",
    "Z2 = Z[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738b480c",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "plt.xlabel('Z1')\n",
    "plt.ylabel('Z2')\n",
    "for i in range(len(A1)):\n",
    "    plt.arrow(0,0, A1[i]*max(Z1), A2[i]*max(Z2), color = 'k', width = 0.0005, head_width = 0.0025)\n",
    "    plt.text(A1[i]*max(Z1)*1.2, A2[i]*max(Z2)*1.2, df.columns[i], color = 'k')\n",
    "plt.scatter(Z[idx_Alpha,0], Z[idx_Alpha,1], c='r', label='Alpha (0)')\n",
    "plt.scatter(Z[idx_Beta,0], Z[idx_Beta,1], c='g', label='Beta (1)')\n",
    "plt.scatter(Z[idx_Gaama,0], Z[idx_Gaama,1], c='b', label='Gaama (2)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439d8095",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y.value_counts().plot(kind='bar', rot=0)\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f04582",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.figure()\n",
    "ax = sns.boxplot(data=df, orient=\"v\", palette=\"Set2\")\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33587bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.figure()\n",
    "ax = sns.boxplot(data=df, orient=\"v\", palette=\"Set2\")\n",
    "ax = sns.stripplot(data=df, color=\".25\")\n",
    "ax.set_xticklabels(ax.get_xticklabels(),rotation=45);\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd0713f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b13c49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfc = df - df.mean() #centered data\n",
    "ax = sns.heatmap(dfc.cov(), cmap='RdYlGn_r', linewidths=0.5, annot=True, cbar=False, square=True)\n",
    "plt.yticks(rotation=0)\n",
    "ax.tick_params(labelbottom=False,labeltop=True)\n",
    "ax.set_xticklabels(ax.get_xticklabels(),rotation=0);\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335c27ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using PCA Library\n",
    "from pca import pca\n",
    "# Initialize and keep all PCs\n",
    "model = pca()\n",
    "# Fit transform\n",
    "out = model.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00ed438",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the top features. The results show that f1 is best, followed by f2 etc\n",
    "print(out['PC'])\n",
    "model.scatter(label = True, legend = False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ec77d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = out['loadings'].T\n",
    "print(A)\n",
    "model.biplot3d(color_arrow='k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b1ad0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "comps = pd.DataFrame(A, columns = variables)\n",
    "ax = sns.heatmap(comps,cmap='RdYlGn_r', linewidths=0.5, annot=True, cbar=True, square=True)\n",
    "ax.tick_params(labelbottom=False,labeltop=True)\n",
    "plt.xticks(rotation=90)\n",
    "plt.title('Principal components')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de949251",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'PC1:{A1}')\n",
    "print(f'PC2:{A2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afce9d32",
   "metadata": {},
   "source": [
    "Test-Train Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5805681",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df, Y, test_size=0.3, random_state=0)\n",
    "print(f'Train Dataset Size: {X_train.shape[0]}')\n",
    "print(f'Test Dataset Size: {X_test.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312574b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_train, Z_test, zy_train, zy_test = train_test_split(Z, Y, test_size=0.3, random_state=0)\n",
    "Z12_train, Z12_test, z12y_train, z12y_test = train_test_split(Z[:,:2], Y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273302c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the evaluation metric\n",
    "scoring = ['f1_macro']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df40403e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NV classifier\n",
    "gnb = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc1be9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [('FULL DATA', X_train, y_train, X_test, y_test), ('Z', Z_train, zy_train, Z_test, zy_test),\n",
    "            ('Z12', Z12_train, z12y_train, Z12_test, z12y_test)]\n",
    "for i, (name, Xtr, ytr, Xtst, ytst) in enumerate(datasets):\n",
    "    gnb.fit(Xtr, ytr)\n",
    "    y_pred = gnb.predict(Xtst)\n",
    "    gnb_score = gnb.score(Xtst, ytst)\n",
    "\n",
    "    # Classification Report\n",
    "    print(f'DATASET: {name}')\n",
    "    print('Classification Report:')\n",
    "    print(classification_report(ytst, y_pred, digits=3))\n",
    "\n",
    "    # Confusion Matrix\n",
    "    cm_gnb = confusion_matrix(y_true=ytst, y_pred=y_pred)\n",
    "    ax = sns.heatmap(cm_gnb, cmap='RdYlGn_r', linewidths=0.5, annot=True, square=True)\n",
    "    plt.yticks(rotation=0)\n",
    "    ax.tick_params(labelbottom=False, labeltop=True)\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), rotation=0)\n",
    "    # plt.title('Naive Bayes Confusion Matrix')\n",
    "    plt.show()\n",
    "\n",
    "    # ADAPTED FROM: https://scikit-learn.org/stable/auto_examples/ensemble/plot_voting_decision_regions.html#sphx-glr-auto-examples-ensemble-plot-voting-decision-regions-py\n",
    "    if name == 'Z12':\n",
    "        # Plotting decision regions\n",
    "        x_min, x_max = Xtr[:, 0].min() - 1, Xtr[:, 0].max() + 1\n",
    "        y_min, y_max = Xtr[:, 1].min() - 1, Xtr[:, 1].max() + 1\n",
    "        xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.01), np.arange(y_min, y_max, 0.01))\n",
    "\n",
    "        Z = gnb.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "        Z = Z.reshape(xx.shape)\n",
    "\n",
    "        plt.contourf(xx, yy, Z, alpha=0.4)\n",
    "        plt.scatter(Xtr[:, 0], Xtr[:, 1], c=ytr, s=20, edgecolor=\"k\", label='Train Set')\n",
    "        plt.scatter(Xtst[:, 0], Xtst[:, 1], c=ytst, marker='^', s=20, edgecolor=\"k\", label='Test Set')\n",
    "        plt.xlabel('')\n",
    "        plt.ylabel('')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "        print(np.where(ytst != y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef1b30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN\n",
    "# Hyperparameter grid search for k\n",
    "param_grid = {'n_neighbors': [2, 4, 8, 16, 32]}\n",
    "knn = KNeighborsClassifier()\n",
    "grid_search = GridSearchCV(knn, param_grid, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4aa1126",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find best k\n",
    "knn_full_data = grid_search.fit(X_train, y_train)\n",
    "knn_Z = grid_search.fit(Z_train, zy_train)\n",
    "knn_Z12 = grid_search.fit(Z12_train, z12y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76d8f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get best k\n",
    "print('Grid Search Results:')\n",
    "k_full_data = knn_full_data.best_params_\n",
    "k_Z = knn_Z.best_params_\n",
    "k_Z12 = knn_Z12.best_params_\n",
    "print(f'k_full_data: {k_full_data}\\nk_Z: {k_Z}\\nk_Z12: {k_Z12}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed26df83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply best k\n",
    "knn = KNeighborsClassifier(n_neighbors=k_full_data.get('n_neighbors'))\n",
    "scores_knn_full_data = cross_validate(knn, X_train, y_train, cv=5, scoring=scoring)\n",
    "scores_knn_Z = cross_validate(knn, Z_train, zy_train, cv=5, scoring=scoring)\n",
    "scores_knn_Z12 = cross_validate(knn, Z12_train, z12y_train, cv=5, scoring=scoring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf97715",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_scores_dict = {}\n",
    "for i in ['fit_time', 'test_f1_macro']:\n",
    "    knn_scores_dict[\"knn_full_data \" + i] = scores_knn_full_data[i]\n",
    "    knn_scores_dict[\"knn_Z  \" + i] = scores_knn_Z[i]\n",
    "    knn_scores_dict[\"knn_Z12 \" + i] = scores_knn_Z12[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fdd1c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_scores_data = pd.DataFrame(knn_scores_dict).T\n",
    "# knn_scores_data['avgs'] = knn_scores_data.mean(axis=1)\n",
    "print(f'{knn_scores_data}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c0757f",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [('FULL DATA', X_train, y_train, X_test, y_test), ('Z', Z_train, zy_train, Z_test, zy_test),\n",
    "            ('Z12', Z12_train, z12y_train, Z12_test, z12y_test)]\n",
    "for i, (name, Xtr, ytr, Xtst, ytst) in enumerate(datasets):\n",
    "    # Apply on train-test split\n",
    "    knn.fit(Xtr, ytr)\n",
    "    y_pred = knn.predict(Xtst)\n",
    "    knn_score = knn.score(Xtst, ytst)\n",
    "    # print(f'\\nTest Set Accuracy: {knn_score:.3f}')\n",
    "\n",
    "    # Classification Report\n",
    "    print(f'DATASET: {name}')\n",
    "    print('Classification Report:')\n",
    "    print(classification_report(ytst, y_pred, digits=3))\n",
    "\n",
    "    # Confusion Matrix\n",
    "    cm_knn = confusion_matrix(y_true=ytst, y_pred=y_pred)\n",
    "    ax = sns.heatmap(cm_knn, cmap='RdYlGn_r', linewidths=0.5, annot=True, square=True)\n",
    "    plt.yticks(rotation=0)\n",
    "    ax.tick_params(labelbottom=False, labeltop=True)\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), rotation=0)\n",
    "    # plt.title('KNN Confusion Matrix')\n",
    "    plt.show()\n",
    "\n",
    "    # ADAPTED FROM: https://scikit-learn.org/stable/auto_examples/ensemble/plot_voting_decision_regions.html#sphx-glr-auto-examples-ensemble-plot-voting-decision-regions-py\n",
    "    if name == 'Z12':\n",
    "        # Plotting decision regions\n",
    "        x_min, x_max = Xtr[:, 0].min() - 1, Xtr[:, 0].max() + 1\n",
    "        y_min, y_max = Xtr[:, 1].min() - 1, Xtr[:, 1].max() + 1\n",
    "        xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.01), np.arange(y_min, y_max, 0.01))\n",
    "\n",
    "        Z = knn.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "        Z = Z.reshape(xx.shape)\n",
    "\n",
    "        plt.contourf(xx, yy, Z, alpha=0.4)\n",
    "        plt.scatter(Xtr[:, 0], Xtr[:, 1], c=ytr, s=20, edgecolor=\"k\", label='Train Set')\n",
    "        plt.scatter(Xtst[:, 0], Xtst[:, 1], c=ytst, marker='^', s=20, edgecolor=\"k\", label='Test Set')\n",
    "        plt.xlabel('')\n",
    "\n",
    "        plt.ylabel('')\n",
    "\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "        # print(np.where(ytst != y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a5a1ee",
   "metadata": {},
   "source": [
    "ADAPTED FROM: https://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html#sphx-glr-auto-examples-model-selection-plot-roc-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc72c0e8",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "datasets = [('FULL DATA', X_train, y_train, X_test, y_test), ('Z', Z_train, zy_train, Z_test, zy_test), ('Z12', Z12_train, z12y_train, Z12_test, z12y_test)]\n",
    "for i, (name, X_tr, y_tr, X_tst, y_tst) in enumerate(datasets):\n",
    "  # Binarize the labels\n",
    "  y_train = label_binarize(y_tr, classes=[0, 1, 2])\n",
    "  y_test = label_binarize(y_tst, classes=[0, 1, 2])\n",
    "  n_classes = y_train.shape[1]\n",
    "  print(f'DATASET: {name}')\n",
    "\n",
    "  list_algos = [gnb, knn]\n",
    "  algo_name = ['Naive Bayes', 'K-Nearest Neighbors']\n",
    "  for i, (algo, algo_name) in enumerate(zip(list_algos, algo_name)):\n",
    "    classifier = OneVsRestClassifier(algo)\n",
    "    y_pred = classifier.fit(X_tr, y_train).predict(X_tst)\n",
    "    # Compute ROC curve and ROC area for each class\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_test[:,i], y_pred[:,i], drop_intermediate=False)\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "    # Compute micro-average ROC curve and ROC area\n",
    "    fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_pred.ravel(), drop_intermediate=False)\n",
    "    roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "    # First aggregate all false positive rates\n",
    "    all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "\n",
    "    # Then interpolate all ROC curves at this points\n",
    "    mean_tpr = np.zeros_like(all_fpr)\n",
    "    for i in range(n_classes):\n",
    "        mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "    # Finally average it and compute AUC\n",
    "    mean_tpr /= n_classes\n",
    "\n",
    "    fpr[\"macro\"] = all_fpr\n",
    "    tpr[\"macro\"] = mean_tpr\n",
    "    roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "    # Plot all ROC curves\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    plt.plot(fpr[\"micro\"], tpr[\"micro\"], label=f'micro-average ROC curve (area = {roc_auc[\"micro\"]:0.2f})', color=\"deeppink\", linestyle=':')\n",
    "    plt.plot(fpr[\"macro\"], tpr[\"macro\"], label=f'macro-average ROC curve (area = {roc_auc[\"macro\"]:0.2f})', color=\"navy\", linestyle=':')\n",
    "\n",
    "    colors = cycle(['c', 'm', 'r'])\n",
    "    for i, color in zip(range(n_classes), colors):\n",
    "        plt.plot(fpr[i],tpr[i], color=color,label=f'ROC curve of class {i} (area = {roc_auc[i]:0.2f})')\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], \"k--\")\n",
    "    plt.xlim([-0.1, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(f'{algo_name}')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53fad73d",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# ADAPTED FROM: https://matplotlib.org/3.1.1/gallery/lines_bars_and_markers/barchart.html\n",
    "def autolabel(rects):\n",
    "    for r in rects:\n",
    "        height = r.get_height()\n",
    "        ax.annotate(f'{height}', xy=(r.get_x() + r.get_width() / 2, height), xytext=(0, 3), textcoords=\"offset points\", ha='center', va='bottom')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff43ebe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_groups = 3\n",
    "ind = np.arange(n_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec9696d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# F1 Scores from above\n",
    "NB = (0.900, 0.060, 0.093)\n",
    "KNN = (0.167, 0.073, 0.087)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9bc0c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create plot\n",
    "fig, ax = plt.subplots(figsize=(10,7))\n",
    "index = np.arange(n_groups)\n",
    "bar_width = 0.20\n",
    "opacity = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1face1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rects1 = plt.bar(index, NB, bar_width, alpha=opacity, color='b', label='Naive Bayes')\n",
    "rects2 = plt.bar(index + bar_width, KNN, bar_width, alpha=opacity, color='y', label='K-Nearest Neighbors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dcaa5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax.set_xlabel('Data Set')\n",
    "ax.set_ylabel('Macro-F1 Scores')\n",
    "#plt.title(f'')\n",
    "plt.xticks(index + bar_width, ('Original Data', 'All PCs', 'Two PCs'))\n",
    "plt.legend(loc=\"upper right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd143bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "autolabel(rects1)\n",
    "autolabel(rects2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead7fcf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5be5305",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0221a80f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
